# 스파크?
아파치 스파크는 범용적이면서도 빠른 속도로 작업을 수행할 수 있도록 설계한 클러스터용 데이터 처리 플렛폼이다.

## 범용적?
스파크는 기존에 각각 분리된 분산 시스템에서 돌아가던 배치, 반복 알고리즘, 대화형 쿼리, 스트리밍 과같은 다양한 타입의 작업들을 동시에 커버할 수 있게 설계되어있다. 단일 시스템에서 다양한 워크로드를
지원함으로써 실제의 데이터 분석 파이프라인에서 다양항 작업들을 연계하기 쉬워진다.

### 어떻게 다양한 타입의 작업들을 동시에 커버할 수 있게 설계되었나?
스파크 프로젝트는 밀접하게 연동된 여러개의 컴포넌트로 구성해서 사용할 수 있다.
이렇게 필요 컴포넌트를 구성해서 사용하는 방식의 설계는 크게 두가지 장점을 가지는데
- 고수준의 컴포넌트들의 성능향상이 이 모듈을 사용하는 다른 하위 컴포넌트의 수정없이도 성능향상에 도움을 줄 수 있다.
- 각 모듈별 요구 상황에 따라서 필요한 모듈만 선택해서 사용, 확장이 가능해진다. 예를 들어 처음에는 검증을 위해 대화형 쿼리로 데이터를 조회하다가 검증 완료 후에는 어플리케이션에서 배치형태로 실행하는 식으로
 필요에 따라 확장을 하면 된다.


## 빠른 속도?
스파크는 맵리듀스가 반복적인 대화형 연산 작업에는 비효율적인 구조임을 착안하여 개발된 오픈소스 프로젝트이다.

## 어떻게 맵리듀스보다 뛰어난 성능을 가질 수 있었나?
- 인메모리
- lazy evaluation
- 장애극복과 캐싱


## 스파크의 중요 모듈들
어떤 컴포넌트로 구성되어 있는지 보자.

### 스파크 코어(Spark Core)
작업 스케줄링,메모리 관리,장애 복구,저장 장치 연동 등등 기본적인 기능들로 구성된다. RDD API의 기반이 되며, 이 API는 RDD 모음들을 생성하고 조작할 수 있는 API를 지원한다.

### 스파크 SQL
스파크 SQL은 정형 데이터를 처리하기 위한 스파크 모듈로, SQL 뿐만 아니라 하이브 테이블, JSON 등 다양한 데이터 소스를 지원한다.

### 스파크 스트리밍
실시간 데이터 스트링을 처리 가능하게 해주는 스파크 컴포넌트이다. RDD API와 비슷한 형태의 스트림 조작 API를 지원한다.

### MLlib
스파크는 Machine Learning 기능을 가지고 있는 라이브러리와 함께 배포된다. Classification, regression, clustering, collaborative filtering 등
다양한 타입의 머신러닝 알고리즘 뿐만 아니라 gradient descent 와 같은 최적화 알고리즘도 지원한다.

### 그래프 X
그래프를 다루기 위한 라이브러리로 그래프 X도 스파크 스트리밍,스파크 SQL과 마찬가지로 RDD API를 확장하였다.

### 클러스터 매니저
스파크는 한 노드에서 수천 노드까지 효과적으로 성능을 확장할 수 있도록 만들어졌다. 많은 노드의 메모리 관리의 가용성을 극대화 하기 위해서 하둡의 YARN, Apache Mesos 등 다양한 클러스터 매니저
위에서 동작할 수 있다.



